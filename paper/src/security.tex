\section{Security Analysis} \label{sec:security}
We base our security analysis on the phases of CTor, see
Figure~\ref{fig:overview}, in the context of our adversary model, see
Section~\ref{sec:adversary}.

\subsection{Phase 0: Consensus} \label{sec:security:phase0}
Directory authorities fetch STHs from attacker-controlled logs and agree upon
which ones to use via deterministic rules, so the attacker is in full control of
which STHs go into the Tor consensus.  Once an STH is announced, it follows from
Tor's threat model that it is fixed because a threshold of directory authorities
are benign.  As such, CTRs have access to the same set of STHs and thus they
also get the same (in)consistent view of the CT landscape. Any inconsistent view
that makes it into the Tor consensus is trivially detected because all STHs are
public and can be audited for consistency by any interested party.  The attacker
should therefore be deterred from creating internal split-views within the Tor
network: at least one announced auditor would detect it and make the log's
misbehavior public.

\subsection{Phase 1: Website to Tor Browser} \label{sec:security:phase1}
The input to phase 1 is the SFO that the attacker wishes to omit as part of
performing a MitM. Assume that the SFO is selected for submission to a CTR.
There are two possible cases: either the SFO is larger than
\texttt{ct-max-sfo-bytes} or it is not. If it is larger, then Tor Browser blocks
until the SFO is at the CTR and the circuit is closed. Assuming no forensic
traces in tor or Tor Browser (can we find a reference based on TB/tor design to
makes us believe it's hard to figure out past circuits?), if the attacker
compromises Tor Browser afterwards the identity of the CTR that received the SFO
is unknown. If the SFO is smaller or equal to \texttt{ct-max-sfo-bytes}, then we
have a race between the time it takes for for Tor Browser to submit the SFO as
well as close the circuit and the time it takes for the attacker to compromise
Tor Browser. We consider the distinction between preventing the SFO from being
sent and revealing the identity of the recipient CTR largely irrelevant; it is
likely that an attacker given hours or days (depending on MMD and
attacker-controlled timestamps in the SFO) to crash or compromise a CTR will
succeed.

Our analysis of the size of SFOs shows that XX. A conservative value for
\texttt{ct-max-sfo-bytes} of YY bytes would rarely lead to any Tor Browser
blocking. Clearly, for an attacker, no blocking is preferable so we assume an
attacker that constructs a SFO of size \texttt{ct-max-sfo-bytes}. This requires
at least ZZ cells to be transported over the circuit to the CTR before it can be
closed (when can we close it? Is it possible to push the data and close it
locally before getting an ack?).

\subsection{Phase 2: Storage at CTR} \label{sec:security:phase2}
In this phase the CTR is temporarily stored at the CTR. The window that that the
attacker can intervene before an SFO is audited by a CTR is governed by its
\texttt{audit\_after} timestamp.  The attacker controls the log's MMD and the
SCT's timestamp, which means that the minimum value of the \texttt{audit\_after}
timestamp is also controlled.  To maximize the attack window to at least an MMD,
the attacker should use a newly issued SCT.

Reaching this phase, we assume that the attacker does not know the CTR holding
the SFO in question. Performing a network-wide DoS of all CTRs is not within
Tor's threat model. A less powerful attack is to perform a flooding attack to
flush each CTR, see Section~\ref{todo}. Such an attack is detectable: the number
of circuits in the Tor network would explode because SFOs are submitted
separately, and CTRs publish flushing statistics in their extra-info documents.
While it is nontrivial to attribute flushing activities to an identifiable
attacker, being able to confirm the \emph{lack of flushing} is an invaluable
property.

\subsection{Phase 3: Auditing} \label{sec:security:phase3}
During the auditing phase, we assume that the attacker has tagged every CTR with
an overwhelming (relative to expected load) number of SFOs (see
Section~\ref{sec:adversary}). Since our auditing Algorithm (see
Section~\ref{sec:design:ctr:audit}) re-uses the circuit to the CT log for
performance reasons, this means that it is reasonable to assume that the
attacker can identify the CTR at the point in time of attempting to audit the
SFO the attacker wants to omit (on the SFO hitting the attacker-controlled CT
log API endpoint). The key question becomes if the attacker can prevent the CTR
from reporting the SFO to the auditor in about \texttt{ct-query-timeout} time.

The attacker could DoS the identified CTR or attempt to compromise it within
\texttt{ct-query-timeout} time. (Similar as for TB, can we find a way where we
can say that we can send data out on an established circuit with only outgoing
traffic? A DoS would only create overwhelming incoming traffic.)

\subsection{Phase 4: Reporting} \label{sec:security:phase4}
The final opportunity to intervene once the \texttt{ct-query-timeout} triggers
is to target the announced auditors.  Our design does nothing to enhance auditor
availability.  As such, we rely on there being a diverse set of auditors that
are difficult to DoS all at once.  Notably it might be the case that the
attacker can win some time by making some auditors unavailable and thus forcing
CTR-to-Auditor resubmissions, but at the same time it is not \emph{reliable}
since CTRs sample their auditors.
