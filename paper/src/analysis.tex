\section{Security Analysis} \label{sec:analysis}

\subsection{Impact of Being Detected} \label{sec:analysis:impact}
Given a man-in-the-middle attack against Tor Browser we consider four
different scenarios of \emph{impact}, namely:
\begin{description}
	\item[None:] the attack was undetected or detected without knowing any
		details as to how it was carried out.
	\item[Minor:] the attack was detected due to some cover-up that involved
		network-wide actions against CTor.  This is likely hard to attribute to
		the actual attacker, but nevertheless it draws much unwanted attention.
	\item[Significant:] the attack generated public cryptographic evidence
		that proves CA misbehavior.
	\item[Catastrophic:] the attack generated public cryptographic evidence
		that proves CT log misbehavior.
\end{description}

Our base design achieves a significant impact level against risk-averse
attackers in our threat model.  The extended designs in
Sections~\ref{sec:auditor}--\ref{sec:log} aim higher, making it possible
to enforce catastrophic impact for the attacker.

\subsection{Probability of Being Detected} \label{sec:analysis:pr}
Suppose the attacker mis-issued a certificate chain that is rooted in Tor
Browser's trust store, and that it is accompanied by enough SCTs from
attacker-controlled CT logs to pass Tor Browser's CT policy.  The resulting SFO
is further used to man-in-the-middle a single Tor Browser user.  Clearly, the
attacker-controlled CT logs have no intention to keep any promise of public
logging as that would trivially imply significant impact.  The attacker's risk
of significant exposure is instead bound by the probability that \emph{any} of
the three phases in our design fails to propagate the mis-issued SFO to a benign
independent CT log.  We analyze each phase separately.

In sum the risk of exposure can never be higher than the probability that Tor
Browser submits an SFO to a genuine CTR successfully, and that risk decreases
proportionally with the attacker's increased capability to operate or DoS CTRs
as well as independent CT logs.

\subsubsection{Phase~1: Submission} \label{sec:analysis:pr:phase1}
The probability of detection cannot exceed the value of \texttt{ct-submit-pr}.
We focus our analysis on the scenario where the
attacker's mis-issued SFO is audited further.  There are two cases to consider,
namely, the mis-issued SFO is either larger than \texttt{ct-max-sfo-bytes} or it
is not.

If the SFO is larger than \texttt{ct-max-sfo-bytes}, Tor Browser blocks until
the SFO is submitted and its CT circuit is closed.  As such, it is impossible to
serve a Tor Browser exploit reactively over the man-in-the-middled connection
that shuts-down the submission procedure before it occurs.  Assuming that
forensic traces in tor and Tor Browser are unreliable,\footnote{%
	``tor'' (aka ``little-t tor'' is the tor process TB uses to interact
        with the Tor network.
        On marking a circuit as closed in tor, tor immediately schedules the
	associated data structures to be freed as soon as possible.
} the sampled CTR identity also cannot be revealed with high certainty
afterwards by compromising Tor Browser.  The attacker may know that the SFO is
stored by \emph{some CTR} based on timing, i.e., blocking-behavior is likely
measurable and distinct.  The important part is not to reveal \emph{which CTR}
received a submission:  a single Tor relay may be subject to DoS.

If the SFO is smaller or equal to \texttt{ct-max-sfo-bytes}, then there is a
race between (i) the time it takes for Tor Browser to submit the SFO and close
its CT circuit against (ii) the time it takes for the attacker to compromise Tor
Browser and identify the CTR in question.  It is more advantageous to try and
win this race rather than being in the unfruitful scenario above.  Therefore,
the attacker would maximize the time it takes to perform (i) by sending an SFO
that is \texttt{ct-max-sfo-bytes}.  Our design reduced the threat of an attacker
that wins this race by using pre-built CT circuits that are closed immediately
after use.  This makes the attack surface \emph{narrow}, limiting the number of
reliable exploits (if any).

Note that the attack surface could, in theory, be eliminated by setting
\texttt{ct-max-sfo-bytes} to infinity.  It is too costly in terms of TLS
handshake latency, however.

\subsubsection{Phase~2: Storage} \label{sec:analysis:pr:phase2}
The probability of detection cannot exceed $1-(f_{\mathsf{ctr}} +
f_{\mathsf{dos}})$, where $f_{\mathsf{ctr}}$ is the fraction of
malicious CTRs and $f_{\mathsf{dos}}$ the fraction of CTRs that suffer from
DoS.  We analyze the case of successful submission to a genuine CTR.

The time that an SFO is stored is governed by randomness in the
\texttt{audit\_after} timestamp~$t$ as well as the back-off delay~$d$,
which combined is in the order of minutes
	(Section~\ref{sec:base:consensus:params}).
The attacker might try to increase the storage time by making the CT landscape
unavailable, forcing additional back-off times and resubmissions.  The attacker
does not know which independent log to target, however.  Since it is not within
our threat model to DoS a significant fraction of CT logs simultaneously, any
attempt to increase the storage time will be unreliable and thus of little use
for our attacker.

The attacker might still try to intervene within the time window at hand, which
involves some method that deletes the mis-issued SFO that is stored somewhere.
Fortunately, it is not known which CTR to target.
%	an attacker that infers the sampled CTR reliably from observing a large
%	majority of the Tor network is not within our threat model.
This means that any attempt to intervene must target all CTRs.  It is clearly
not within Tor's threat model to DoS each and every CTR.  A less intrusive
approach towards intervention would be to simply submit SFOs, posing as genuine
Tor Browser clients.  If enough SFOs are submitted, CTRs could run out of memory
and therefore be forced to delete at random (Section~\ref{sec:base:phase2}).
The threat of such a flood does not apply here:
	conducting it within minutes implies a network-wide DoS,
	see Section~\ref{sec:auditor:analysis:phase2}.

\subsubsection{Phase~3: Auditing} \label{sec:analysis:pr:phase3}
The probability of detection cannot exceed $1-f_{\mathsf{log}}$, where
$f_{\mathsf{log}}$ is the fraction of seemingly independent but
attacker-controlled CT logs.  We analyze the case of a CTR that sampled a
genuine CT log in phase~2, which remains fixed in the event of transient errors.
Adding a certificate chain to the log as part of the auditing phase does not
leak which CTR holds an SFO \emph{to the attacker} unless all log connections
that leave the Tor network are inspected.\footnote{%
	We have not specified any further verification of the log's TLS certificate,
	which means that the attacker can forge it without detection.  This is not
	true for the returned SCT (if any), but the CTR in question could be
	identified by tagging.  See Section~\ref{sec:auditor:analysis:phase3}.
} The attacker in our threat model is only partially present in the network,
however.  An identifiable CTR can therefore not be targeted reliably before any
resubmission takes place.  Without resubmission or once logging finally
succeeds, the mis-issued certificate is exposed to the public and
\emph{significant impact} is achieved.

TODO: pin keys to establish secure connections with the logs?!
