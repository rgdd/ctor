\section{Security Analysis} \label{sec:analysis}

%\subsection{Impact of Being Detected} \label{sec:analysis:impact}
We consider four types of impact for an attacker that conducted
HTTPS-based man-in-the-middle attacks on Tor Browser.  Other than \emph{none},
these impact types are:
\begin{description}
	\item[Minor] the attack was detected due to some cover-up that involved
		network-wide actions against CTor.  This is likely hard to attribute to
		the actual attacker, but nevertheless it draws much unwanted attention.
	\item[Significant] the attack generated public cryptographic evidence
		that proves CA misbehavior.
	\item[Catastrophic] the attack generated public cryptographic evidence
		that proves CT log misbehavior.
\end{description}

Our design leads to significant and catastrophic impact events, but does
unfortunately not preclude minor ones.  It is possible to overcome this
shortcoming at different trade-offs, e.g., by tuning CTor parameters reactively
(Section~\ref{sec:analysis:pr:phase3}) or relying on different trust
assumptions, as in the scaled-down cross-logging designs in
Section~\ref{sec:incremental}.

\subsection{Probability of Detection} \label{sec:analysis:pr}
Suppose the attacker mis-issued a certificate that Tor Browser trusts, and that
it is considered valid because it is accompanied by enough SCTs from CT logs
that the attacker controls.  The resulting SFO is then used to man-in-the-middle
a single Tor Browser user, i.e., for the purpose of our analysis we consider
\emph{the most risk-averse scenario possible}.  Clearly, none of the attacker's
CT logs plan to keep any promise of public logging:
	that would trivially imply significant impact events.
The risk of exposure is instead bound by the probability that \emph{any} of the
four phases in our design fail to propagate the mis-issued SFO to a pinned CT
auditor that is benign.

%In sum the probability of detection cannot exceed the likelihood that Tor
%Browser submits an SFO to a genuine CTR, which in turn must initiate a report to
%a trusted CT auditor through a genuine watchdog.

\subsubsection{Phase~1: Submission} \label{sec:analysis:pr:phase1} 
The probability of detection cannot exceed the probability of submission
(\texttt{ct-submit-pr}). We analyze the outcome of submitting the mis-issued
SFO from Tor Browser to a CTR\@.  There are two cases to consider, namely, the
mis-issued SFO is either larger than \texttt{ct-large-sfo-size} or it is not.

If the SFO is larger than \texttt{ct-large-sfo-size}, Tor Browser blocks until
the SFO is submitted and its CT circuit is closed.  As such, it is impossible to
serve a Tor Browser exploit reactively over the man-in-the-middled connection
that shuts-down the submission procedure before it occurs.  Assuming that
forensic traces in tor and Tor Browser are unreliable,\footnote{%
	``tor'' (aka ``little-t tor'') is the tor process Tor Browser uses to
	interact with the Tor network.  On marking a circuit as closed in tor, tor
	immediately schedules the associated data structures to be freed as soon as
	possible.
} the sampled CTR identity also cannot be revealed with high certainty
afterwards by compromising Tor Browser.  The attacker may know that the SFO is
buffered by \emph{some CTR} based on timing, i.e., blocking-behavior could be 
measurable and distinct.  The important part is not to reveal \emph{which CTR}
received a submission:  a single Tor relay may be subject to DoS.

If the SFO is smaller or equal to \texttt{ct-large-sfo-size} there is a
race between (i) the time it takes for Tor Browser to submit the SFO and close
its CT circuit against (ii) the time it takes for the attacker to compromise Tor
Browser and identify the CTR in question.  It is more advantageous to try and
win this race rather than being in the unfruitful scenario above.  Therefore,
the attacker would maximize the time it takes to perform (i) by sending an SFO
that is \texttt{ct-large-sfo-size}.  Our design reduced the threat of an
attacker that wins this race by using pre-built CT circuits that are closed
immediately after use.  This makes the attack surface \emph{narrow}, limiting
the number of reliable exploits (if any).

Note that the attack surface could, in theory, be eliminated by setting
\texttt{ct-large-sfo-size} to zero.  However, that is likely  too costly in
terms of latency~\cite{no-hard-fail}.

\subsubsection{Phase~2: Buffering} \label{sec:analysis:pr:phase2}
The probability of detection cannot exceed $1-(f_{\mathsf{ctr}} +
f_{\mathsf{dos}})$, where $f_{\mathsf{ctr}}$ is the fraction of
malicious CTRs and $f_{\mathsf{dos}}$ the fraction of CTRs that suffer from
DoS.  We analyze the outcome of SFO reception at a genuine CTR\@.

The time that an SFO is buffered depends on if the log's MMD elapsed or not.
The earliest point in time that a newly issued SCT can be audited (and the log
is expected to respond) is an MMD later, whereas the normal buffer time is
otherwise only governed by smaller randomness in the \texttt{audit\_after}
timestamp (minutes).  A rational attacker would therefore maximize the buffer
time by using a newly issued SCT, resulting in an attack window that is \emph{at
least} 24~hours for today's CT logs~\cite{google-log-policy}.

Following from Tor's threat model, the mis-issued SFO must be stored in volatile
memory and not to disk.  Two risks emerge due to large buffer times:
	the CTR in question might be restarted by the operator independently of the
		attacker's mis-issued SFO being buffered,
	and given enough time the attacker might find a way to cause the evidence to
		be deleted.
While a risk-averse attacker cannot rely on the former to avoid detection, we
emphasize that the CTR criteria must include the \texttt{stable} flag to reduce
the probability of this occurring.

The latter is more difficult to evaluate.  It depends on the attacker's
knowledge as well as capabilities.  Phase~1 ensured that the attacker \emph{does
not know which CTR to target}.  As such, any attempt to intervene needs to
target all CTRs.  While a network-wide DoS against Tor would be effective, it is
not within our threat model.  A less intrusive type of DoS would be to
\emph{flood} CTRs by submitting massive amounts of SFOs: just enough to make
memory a scarce resource, but without making Tor unavailable. This could
potentially \emph{flush} a target SFO from the CTR's finite memory, following
from the delete-at-random strategy in Section~\ref{sec:base:phase2}. Assuming
that a CTR has at most 1~GiB of memory available for SFOs (conservative and in
favour of the attacker), Appendix~\ref{app:flush} shows that the attacker's
flood must involve at least $2.3$~GiB per CTR to accomplish a 90\% success
certainty.  This means that it takes $7.9$--$39.3$~minutes if the relay
bandwidth is between 8--40~Mbps.  So it is impractical to flush all CTRs within
a few minutes, and hours are needed not to make everyone unavailable at once.

The CTR criteria set in Section~\ref{sec:base:consensus} matches over
4000 Tor relays~\cite{relay-by-flag}.  A network-wide flush that succeeds with
90\% certainty therefore involves 8.99~TiB.  It might sound daunting at first,
but distributed throughout an entire day it only requires 0.91~Gbps. Such an
attack is within our threat model because it does not make Tor unavailable.
Notably the ballpark of these numbers do not change to any significant degree by
assuming larger success probabilities, e.g., a 99\% probability only doubles the
overhead. Further, the needed bandwidth scales linearly with the assumed memory
of CTRs.  This makes it difficult to rely on the finite volatile memory of CTRs
to mitigate network-wide flushes.  As described in
Section~\ref{sec:base:phase2}, we ensure that flushes are \emph{detected} by
publishing the number of received and deleted SFO bytes throughout different
time intervals as extra-info.

Once detected, there are several possible \emph{reactions} that decrease the
likelihood of a minor impact scenario.  For example, Tor's directory
authorities could lower MMDs to, say, 30~minutes, so that the SFO is reported to
an auditor before it is flushed with high probability.  This has the benefit of
implying significant impact because the mis-issued certificate is detected, but
also the drawback of allowing the logs to merge the certificate before there is
any MMD violation to speak of.  The most appropriate response depends on the
exact attack scenario and which trade-offs one is willing to accept.

\subsubsection{Phase~3: Auditing} \label{sec:analysis:pr:phase3}
By the time an SFO enters the audit phase, the log in question is expected to
respond with a valid inclusion proof.  There is no such proof if the log
violated its MMD, and it is too late to create a split-view that merged the
certificate in time because the CTR's view is already fixed by an STH in the
Tor consensus that captured the log's misbehavior.  In fact, creating any
split-view within Tor is impractical because it requires that the consensus is
forged or that nobody ever checks whether the trusted STHs are consistent.
This leaves two options:
	the attacker either responds to the query with an invalid inclusion proof or
	not at all.
The former is immediately detected and starts Phase~4, whereas the latter forces
the CTR to wait for \texttt{ct-watchdog-timeout} to trigger (which is a
few seconds to avoid premature auditor reports).  A rational attacker prefers
the second option to gain time.

Clearly, the attacker knows that \emph{some} CTR holds evidence of log
misbehavior as it is being audited.  The relevant question is whether the
\emph{exact CTR identity} can be inferred, in which case the attacker could
knock it offline (DoS).  Motivated by the threat of \emph{tagging}, where the
attacker sends unique SFOs to all CTRs so that their identities are revealed
once queried for, we erred on the safe side and built watchdogs into our design:
it is already too late to DoS the querying CTR because the evidence is already
replicated somewhere else, ready to be reported unless there is a timely
acknowledgement. The attacker would have to \emph{break into an arbitrary CTR
within seconds} to cancel the watchdog, which cannot be identified later on
(same premise as the sampled CTR in phase~1).  Such an attacker is not in Tor's
threat model.

\subsubsection{Phase~4: Reporting} \label{sec:analysis:pr:phase4} 
At this stage the process of reporting the mis-issued SFO to a random CT auditor
is initiated.  Clearly, the probability of detection cannot exceed
$1-f_{\mathsf{auditor}}$, where $f_{\mathsf{auditor}}$ is the fraction of
malicious CT auditors.  Fixating the sampled CT auditor is important to avoid
the threat of an eventually successful report only if it is destined to the
attacker's auditor because our attacker is partially present in the network.
Gaining time at this stage is of limited help because the CTR identity is
unknown as noted in Section~\ref{sec:analysis:pr:phase3}, and it remains the
case throughout phase~4 due to reporting on independent Tor circuits (and
independently of if other SFO reports succeeded or not).  Without an
identifiable watchdog, the attacker needs a network-wide attack that is already
more likely to succeed during the lengthy buffer phase.
