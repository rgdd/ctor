\section{Background} \label{sec:background}

\subsection{Certificate Transparency} \label{sec:background:ct}
The idea to transparently log TLS certificates emerged at Google in response to
a lack of proposals that could be deployed without drastic ecosystem changes
and/or significant downsides~\cite{ct/a}.  In reality, CT is about logging
certificate \emph{chains}:
	a domain owner's certificate is signed by an intermediate CA, whose
	certificate is in turned signed by a root CA that acts as a trust
	anchor~\cite{ca-ecosystem}.
The resulting certificate chain is composed of the domain owner's leaf
certificate, the intermediate CA certificate, and the root CA certificate.
Trust anchors are shipped in software, such as web browsers and operating
systems.

\subsubsection{Cryptographic Foundation}
The operator of a CT log maintains a tamper-evident append-only Merkle
tree~\cite{ct,ct/bis}.  At any time, a Signed Tree Head (STH) can be produced
which fixes the log's structure and content.  Important attributes of an STH
include
	the tree head (a cryptographic hash),
	the tree size (a number of entries), and
	the current time.
Given two tree sizes, a log can produce a \emph{consistency proof} that proves
the newer tree head entails everything that the older tree head does.  As such,
anyone can verify that the log is append-only without downloading all entries
and recomputing the tree head.  Membership of an entry can also be proven
by producing an \emph{inclusion proof} for an STH\@.  These proof techniques are
formally verified~\cite{secure-logging-and-ct}.

Upon a valid request, a log must add an entry and produce a new STH that covers
it within a time known as the Maximum Merge Delay (MMD), e.g., 24~hours.  This
policy aspect can be verified because in response, a Signed Certificate
Timestamp (SCT) is returned.  An SCT is a signed promise that an entry will
appear in the log within an MMD.  A log that violates its MMD is said to perform
an \emph{omission attack}.  It can be detected by challenging the log to prove
inclusion.  A log that forks, presenting one append-only version
to some entities and another to others, is said to perform a \emph{split-view
attack}.  Split-views can be detected by STH
gossip~\cite{chuat,dahlberg,nordberg,syta}.

\subsubsection{Standardization}
The standardized CT protocol defines public HTTP(S) endpoints that allow anyone
to check the log's accepted trust anchors and added certificates, as well as
obtaining the most recent STH and fetching proofs~\cite{ct,ct/bis}.  For
example, the \texttt{add-chain} endpoint returns an SCT if the added certificate
chain ends in a trust anchor returned by the \texttt{get-roots} endpoint.  We
use the \texttt{add-chain} endpoint in Section~\ref{sec:base}, and the
\texttt{get-proof-by-hash} as well as the \texttt{get-sth} endpoints in
Section~\ref{sec:auditor}.  The \texttt{get-proof-by-hash} endpoint takes as
input a leaf certificate hash and an STH's tree size, which indicates the tree
head that the log should base its inclusion proof on.  The proof is valid if it
can be used in combination with the certificate to reconstruct the tree head of
some STH.

\subsubsection{Verification}
The CT landscape provides a limited value unless it is verified that the logs
play by the rules.  The rules are largely influenced by major browser vendors
that define CT policies.  For example, how is CT enforced by their user agents,
and what is required to become a recognized CT log in terms of uptime
requirements and accepted trusted anchors.  Google's Chrome and Apple's Safari
require that a certificate chain must be accompanied by two independent
SCTs~\cite{chrome-policy,safari-policy}.  Independence refers to the associated
log operators.  While there are several ways that
a log can misbehave with regards to these policy aspects, the most fundamental
forms of cheating are omission and split-view attacks:
	it would undermine detection of mis-issued TLS certificates.
A party that follows-up on inclusion and consistency proofs is said to
\emph{audit} the logs.  Wide-spread client-side auditing is a premise for CT
logs to be untrusted, but none of the web browsers that enforce CT engage in
such activities yet.  For example, it is difficult due privacy
concerns~\cite{ct-with-privacy}.  CT also assumes that domain owners
\emph{monitor} the logs for mis-issuance by inspecting the added
certificates~\cite{lwm,ct-monitors}.

\subsection{Tor} \label{sec:background:tor}

Most of the activity of Tor's millions of daily users starts with Tor Browser
(TB) and connects to some ordinary website via a circuit comprised of three
randomly-selected Tor relays. In this way no identifying information from
Internet protocols (such as IP address) are automatically provided to the
destination, and no single entity can observe both the source and destination of
a connection. TB is also configured and performs some filtering to resist
browser fingerprinting, and first party isolation to resist sharing state or
linking of identifiers across origins. More generally it avoids storing
identifying configuration and behavioral information to disk.

Tor relays in a circuit are selected at random, but not uniformly. A typical
circuit is comprised of a \emph{guard}, a \emph{middle}, and an \emph{exit}. A
guard is selected by a client and used for several months as the entrance to all
Tor circuits. If the guard is not controlled by an adversary, that adversary
will not find itself selected to be on a Tor circuit adjacent to (thus
identifying) the client. And because some relay operators do not wish to act as
the apparent Internet source for connections to arbitrary websites, relay
operators can configure the ports (if any) on which they will permit connections
besides to other Tor relays. Finally, to facilitate load balancing, relays are
assigned a weight based on their apparent capacity to carry traffic. In keeping
with avoiding storing of linkable state, even circuits that share an origin will
only permit new connections over that circuit for ten minutes. After that, if
all connections are closed, all state associated with the circuit is cleared.
Similarly, at each relay state associated with a given circuit is cleared
shortly after a circuit is closed.

Tor clients use this information when choosing relays with which to build a
circuit. They receive the information via an hourly updated \emph{consensus}.
The consensus assigns weight as well as flags such as \texttt{guard} or
\texttt{exit} along with auxiliary flags such as \texttt{stable}, which, e.g.,
is necessary to obtain the \texttt{guard} flag since guards must have good
availability. Self-reported information by relays in their \emph{extra-info
document}, such as statistics on their read and written bytes, are also part of
the consensus and uploaded to \emph{directory authorities}. Directory
authorities determine the consensus by voting on various components making up
the shared view of the state of the Tor network. Making sure that all clients
have a consistent view of the network prevents epistemic attacks wherein clients
can be separated based on the routes that are consistent with their
understanding~\cite{danezis:pets2008}. This is only a very rough sketch of Tor's
design and operation.  More details can be found by following links at Tor's
documentation site~\cite{tor-documentation}.

Tor does not aim to prevent end-to-end correlation attacks. An adversary
controlling the guard and exit, or controlling the destination and observing the
client ISP, etc. is assumed able to confirm who is connected to whom on that
particular circuit. The Tor adversary model assumes an adversary able to control
and/or observe a small to moderate fraction of Tor relays measured by both
number of relays and by consensus weight, assumes a large number of Tor clients
able to, for example, flood individual relays to detect traffic signatures of
honest traffic on a given circuit~\cite{long-paths}. Also, the adversary can
knock any small number of relays offline via either attacks from clients or
direct Internet DDoS\@. 
