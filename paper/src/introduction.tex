\section{Introduction} \label{sec:introduction}
Metrics reported by Google and Mozilla reveal that encryption on the web
skyrocketed the past couple of years: at least 84\% of all web pages load using
HTTPS~\cite{google-metrics,mozilla-metrics}. An HTTPS connection is initiated by
a TLS handshake where the client's web browser requires that the web server
presents a valid certificate to authenticate the identity of the server, e.g.,
to make sure that the client who wants to visit \url{mozilla.org} is really
connecting to Mozilla, and not, say, Google. A certificate specifies the
cryptographic key-material for a given domain name, and it is considered valid
if it is digitally signed by a Certificate Authority (CA) that the web browser
trusts.

It is a long-known problem that the CA trust model suffers from
weakest-link security:
	web browsers allow hundreds of CAs to sign arbitrary domain-name to
		key-bindings,
	which means that it suffices to compromise a single CA to acquire any
		certificate~\cite{ca-ecosystem,https-sok}.
Motivated by prominent CA compromises, such as the issuance of fraudulent
certificates for
	\url{*.google.com},
	\url{*.mozilla.org} and
	\url{*.torproject.org}
by DigiNotar~\cite{diginotar}, multiple browser vendors mandated
that certificates issued by CAs must be publicly disclosed in Certificate
Transparency (CT) logs to be valid.  The idea behind CT is that, by making all
CA-issued certificates transparent, mis-issued ones can be detected
\emph{after the fact}~\cite{ct/a,ct,ct/bis}.  The appropriate actions can then
be taken to keep the wider web safe, e.g., by
	investigating the events that lead up to a particular incident,
	removing or limiting trust in the offending CA, and
	revoking effected certificates.
Google Chrome and Apple's Safari currently enforce CT by augmenting the TLS
handshake to require cryptographic proofs from the server that the presented
certificate \emph{will appear} in CT logs that the respective web browsers
trust~\cite{chrome-policy,safari-policy}.

In addition to increased encryption on the web, the ability to access it
anonymously matured as well.  Tor with its Tor Browser has millions of daily
users~\cite{tor,mani}, and efforts are ongoing to mature the technology 
for wider user~\cite{fftor}.  Tor Browser builds on-top of Mozilla's Firefox:
	it relays traffic between the user and the web server in question by routing
		everything through the Tor network,
	which is composed of thousands of voluntary-run relays that are located
		across the globe~\cite{relay-by-flag}.
Just like attackers may wish to break security properties of HTTPS, it may also
be of interest to break the anonymity provided by Tor.  A common technique for
deanonymization (known to be used in practice) is to compromise Tor
Browser instead of circumventing the anonymity provided by
Tor~\cite{selfrando,lepop1,lepop2,zerotor}.  Web browsers like Firefox
(or forks thereof) are one of the most complex software types that is widely
used today, leading to security vulnerabilities and clear incentives for
exploitation.  For example, the exploit acquisition platform Zerodium offers up
to \$$100,000$ for a Firefox zero-day exploit that provides remote code
execution and local privilege escalation (i.e., full control of the
browser)~\cite{zeromain}.

An attacker that wishes to use such an exploit to compromise and then ultimately
deanonymize a Tor Browser user has to deliver the exploit somehow.  Since the
web is mostly encrypted, this primarily needs to take place over an HTTPS
connection where the attacker controls the content returned by the web server.
While there are numerous possible ways that the attacker can accomplish this,
e.g., by compromising a web server that a subset of Tor Browser users visit,
another option is to \emph{impersonate} one or more web servers by acquiring
fraudulent certificates. Due to the Tor network being run by volunteers, getting
into a position to perform such an attack is relatively straightforward:
	the attacker can volunteer to run malicious exit
		relays~\cite{spoiled-onions}.
The same is true for an attacker that wishes to man-in-the-middle connections
made by Tor Browser users.  In some cases a Tor Browser exploit may not even be
needed for deanonymization, e.g., the attacker can observe if the user logs-on
to a service linking an identity.

\subsection{Introducing CTor}
We propose an incrementally deployable and privacy-preserving design that is
henceforth referred to as CTor.  CTor is composed of a base design and two
possible extensions, bringing CT to Tor by modifying how Tor Browser and
relays in the Tor network work.  The goal is to detect HTTPS-based
man-in-the-middle attacks \emph{after the fact} when conducted by an attacker
that:
\begin{enumerate}
	\item can acquire any certificate from a trusted CA,
	\item with the necessary cryptographic proofs from CT logs so that
		Tor Browser accepts the certificate as valid (with no intent of making
		the fraudulent certificate publicly available in any of the logs), and
	\item with the ability to gain full control of Tor Browser shortly after
		establishing an HTTPS connection.
\end{enumerate}

The first and third capabilities are motivated directly by shortcomings in the
CA ecosystem as well as how the anonymity of Tor Browser is known to be attacked.
The second capability assumes the same starting point as Google Chrome and
Apple's Safari, namely, that the logs are trusted to \emph{promise} public
logging, which is in contrast to being untrusted and thus forced to \emph{prove}
it.  This is part of the gradual CT deployment that avoided breakage on the
web~\cite{does-ct-break-the-web}.  CTor therefore follows suit, starting
by relaxing and ultimately eliminating the trust which is currently (mis)placed
in browser-included logs.  For example, an attacker that controls two
independent CT logs trivially bypasses Apple's CT enforcement.  This is not
to say that simply using trusted logs would be an insignificant Tor Browser
improvement when compared to no CT at all, but CTor takes it several steps
further by protecting against increasingly powerful attackers.

Our base design uses the CT landscape against the attacker to ensure a non-zero
(tweakable) probability of public disclosure \emph{each time} a fraudulent
certificate is used against Tor Browser.  This is done by randomly adding a
subset of presented certificates to CT logs that the attacker may not control
(inferred from the accompanied promises of public logging).  Such
\emph{certificate cross-logging} distributes trust across all CT logs,
raising the bar towards unnoticed certificate mis-issuance.
Motivated by deployability, performance, security and privacy implications,
Tor Browser uses Tor relays as intermediates to cache and interact with CT logs
on its behalf.  For example, it ensures that log operators like Google and
Cloudflare get less information regarding browsing activities from Tor (in
addition to what their privileged Internet positions already
provide~\cite{1mtrack,TorDNS}).

The extended CTor designs have in common that their goal is to make violated
promises of public logging transparent, which can otherwise be used to silently trick
today's CT-enforcing web browsers into accepting malicious HTTPS connections.
Disclosing such proofs would likely disqualify each of the offending CT logs and
thus come at great cost to the attacker in terms of lost capabilities:
	even a small probability of detection might entail unacceptable risk of
	exposure.
We already observed instances of CT logs that happened to
	violate their promises of public logging~\cite{gdca1-omission},
	show inconsistent certificate contents to different
		parties~\cite{izenpe-disqualified,venafi-disqualified}, and
	get their secret signing key compromised due to disclosed remote
		code-execution vulnerabilities~\cite{digicert-log-compromised}. 
While there were little or no real-world impact by these incidents, it
show-cases that full trust in CT logs is likely a mistake.

\subsection{Contribution and Structure}
Section~\ref{sec:background} introduces necessary background on CT and Tor.
Section~\ref{sec:adversary} motivates the intended attacker further and presents
our threat model.
Section~\ref{sec:base} describes the base CTor design that enables
	\emph{Tor Browser to probabilistically provide evidence to CT logs that
	fraudulent certificates were presented while preserving privacy}.
This greatly impacts risk-averse attackers because one part of their malicious
behavior become transparent in the CT landscape \emph{if some log operators are
benign}.  For example, the domain name in question is disclosed as part of the
cross-logged certificate, and awareness of the event may draw unwanted
attention.  The security analysis in Section~\ref{sec:analysis} shows that one
of the attacker's best bets would be to attack the entire Tor network and/or all
CT logs:
	an act that would likely draw much unwanted attention.

Sections~\ref{sec:auditor}--\ref{sec:log} present two design extensions that
aim to also make any violated promise of public logging transparent.  The
deployment of either extension
	\emph{would greatly contribute to the open question of how to reduce trust
	in CT log operators},
which is caused by the lack of an appropriate gossip mechanism as well as
privacy issues while interacting with the
logs~\cite{minimal-gossip,nordberg,ct-with-privacy}.
The extended auditing in Section~\ref{sec:auditor}
	\emph{eliminates all trust in the browser-accepted CT logs}
by challenging them to prove certificate inclusion cryptographically, and would
result in a
	\emph{single probabilistically-verified view of the CT log ecosystem
	available from Tor's consensus}.
This view could be used by other browsers as the basis of trust,
	\emph{greatly improving the security posture of the entire web}.
The extended cross-logging in Section~\ref{sec:log} involves only a minor tweak
to the base design, but it is unfortunately to the API of CT logs and not Tor.
Similar changes were already proposed in the context of CT
gossip~\cite{minimal-gossip}.  If supported, Tor relays could expose both the
mis-issued certificates and the logs that promised to include them \emph{without
the complexity of distinguishing between benign and fraudulent certificates}.
We argue that CTor \emph{can be deployed incrementally}:
	complete Firefox's CT support~\cite{ffct},
	add the base CTor design, and finally,
	pick CTor extensions depending on how CT evolves.

We show that circuit-, bandwidth- and memory-\emph{overheads are modest} by
computing such estimates in Section~\ref{sec:performance}.  Therefore, we
do not investigate performance further in any experimental setting.
Section~\ref{sec:privacy} discusses privacy aspects of our design choices,
focusing on the essential role of the Tor network's distributed nature
to preserve user privacy as well as the overall security of our designs.  In
gist, \emph{a similar approach would be privacy-invasive without Tor}, e.g.,
if adopted by Google Chrome.
Section~\ref{sec:related} outlines related work.
Section~\ref{sec:conclusion} concludes the paper.
