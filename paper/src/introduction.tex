\section{Introduction} \label{sec:introduction}
Metrics reported by Google and Mozilla reveal that encryption on the web
skyrocketed the past couple of years: at least 84\% of all web pages load using
HTTPS~\cite{google-metrics,mozilla-metrics}. An HTTPS connection is initiated by
a TLS handshake where the client's web browser requires that the web server
presents a valid certificate to authenticate the identity of the server, e.g.,
to make sure that the client who wants to visit \url{mozilla.org} is really
connecting to Mozilla, and not, say, Google. A certificate specifies the
cryptographic key-material for a given domain name, and it is considered valid
if it is digitally signed by a Certificate Authority (CA) that the web browser
trusts.

It is a long-known problem that the CA trust model suffers from
weakest-link security:
	web browsers allow hundreds of CAs to sign arbitrary domain-name to
		key-bindings,
	which means that it suffices to compromise a single CA to acquire any
		certificate~\cite{ca-ecosystem,https-sok}.
Motivated by prominent CA compromises, such as the issuance of fraudulent
certificates for
	\url{*.google.com},
	\url{*.mozilla.org} and
	\url{*.torproject.org}
by DigiNotar~\cite{diginotar}, multiple browser vendors mandated
that certificates issued by CAs must be publicly disclosed in Certificate
Transparency (CT) logs to be valid.  The idea behind CT is that, by making all
CA-issued certificates transparent, mis-issued ones can be detected
\emph{after the fact}~\cite{ct/a,ct,ct/bis}.  The appropriate actions can then
be taken to keep the wider web safe, e.g., by
	investigating the events that lead up to a particular incident,
	removing or limiting trust in the offending CA, and
	revoking affected certificates.
Google Chrome and Apple's Safari currently enforce CT by augmenting the TLS
handshake to require cryptographic proofs from the server that the presented
certificate \emph{will appear} in CT logs that the respective web browsers
trust~\cite{chrome-policy,safari-policy}.

In addition to increased encryption on the web, the ability to access it
anonymously matured as well.  Tor with its Tor Browser has millions of daily
users~\cite{tor,mani}, and efforts are ongoing to mature the technology 
for wider user~\cite{fftor}.  Tor Browser builds on-top of Mozilla's Firefox:
	it relays traffic between the user and the web server in question by routing
		everything through the Tor network,
	which is composed of thousands of volunteer-run relays that are located
		across the globe~\cite{relay-by-flag}.
Just like attackers may wish to break security properties of HTTPS, it may also
be of interest to break the anonymity provided by Tor.  A common technique for
deanonymization (known to be used in practice) is to compromise Tor
Browser instead of circumventing the anonymity provided by
Tor~\cite{selfrando,lepop1,lepop2,zerotor}.  Web browsers like Firefox
(or forks thereof) are one of the most complex software types that are widely
used today, leading to security vulnerabilities and clear incentives for
exploitation.  For example, the exploit acquisition platform Zerodium offers up
to \$$100,000$ for a Firefox zero-day exploit that provides remote code
execution and local privilege escalation (i.e., full control of the
browser)~\cite{zeromain}.

An attacker that wishes to use such an exploit to compromise and then ultimately
deanonymize a Tor Browser user has to deliver the exploit somehow.  Since the
web is mostly encrypted, this primarily needs to take place over an HTTPS
connection where the attacker controls the content returned by the web server.
While there are numerous possible ways that the attacker can accomplish this,
e.g., by compromising a web server that a subset of Tor Browser users visit,
another option is to \emph{impersonate} one or more web servers by acquiring
fraudulent certificates. Due to the Tor network being run by volunteers, getting
into a position to perform such an attack is relatively straightforward:
	the attacker can volunteer to run malicious exit
		relays~\cite{spoiled-onions}.
The same is true for an attacker that wishes to man-in-the-middle connections
made by Tor Browser users.  In some cases a Tor Browser exploit may not even be
needed for deanonymization, e.g., the attacker can observe if the user logs-on
to a service linking an identity.

\subsection{Introducing CTor}
We propose an incrementally deployable and privacy-preserving design that is
henceforth referred to as CTor.  By bringing CT to Tor, HTTPS-based
man-in-the-middle attacks against Tor Browser can be detected \emph{after the
fact} when conducted by an attacker that:
\begin{enumerate}
	\item can acquire any certificate from a trusted CA,
	\item with the necessary cryptographic proofs from CT logs so that
		Tor Browser accepts the certificate as valid (with no intent of making
		the fraudulent certificate publicly available in any of the logs), and
	\item with the ability to gain full control of Tor Browser shortly after
		establishing an HTTPS connection.
\end{enumerate}

The first and third capabilities are motivated directly by shortcomings in the
CA ecosystem as well as how the anonymity of Tor Browser is known to be
attacked.  The second capability assumes the same starting point as Google
Chrome and Apple's Safari, namely, that the logs are trusted to \emph{promise}
public logging, which is in contrast to being untrusted and thus forced to
\emph{prove} it.  This is part of the gradual CT deployment that avoided
breakage on the web~\cite{does-ct-break-the-web}.  Therefore, we start
from the assumption that Tor Browser accepts a certificate as valid if 
accompanied by two independent promises of public logging.  The limitation of
such CT enforcement is that it is trivially bypassed by an attacker that
controls two seemingly independent CT logs.  This is not to say that trusting
the log ecosystem would be an insignificant Tor Browser improvement when
compared to no CT at all, but CTor takes us several steps further by relaxing
and ultimately eliminating the trust which is currently (mis)placed in today's
browser-recognized CT logs.

The initial design increment uses the CT landscape against the attacker to
ensure a non-zero (tweakable) probability of public disclosure \emph{each time}
a fraudulent certificate is used against Tor Browser.  This is done by randomly
adding a subset of presented certificates to CT logs that the attacker may not
control (inferred from the accompanied promises of public logging).  Such
\emph{certificate cross-logging} distributes trust across all CT logs, raising
the bar towards unnoticed certificate mis-issuance.  Motivated by factors such
as privacy, security and deployability, Tor Browser uses Tor relays as
intermediates to cache and interact with CT logs on its behalf.  For example, it
ensures that log operators like Google and Cloudflare get less information
regarding browsing activities from Tor (in addition to what their privileged
Internet positions already provide~\cite{1mtrack,TorDNS}).

The next increment and the full CTor design have in common that their goal is
to make violated promises of public logging transparent, which can otherwise be
used to silently trick today's CT-enforcing web browsers into accepting
malicious HTTPS connections.  If such proofs are disclosed it would likely
disqualify all offending CT logs and thus come at great cost to the
attacker in terms of lost capability:
	even a small probability of detection might entail unacceptable risk of
	exposure.
We already observed instances of CT logs that happened to
	violate their promises of public logging~\cite{gdca1-omission},
	show inconsistent certificate contents to different
		parties~\cite{izenpe-disqualified,venafi-disqualified}, and
	get their secret signing keys compromised due to disclosed remote
		code-execution vulnerabilities~\cite{digicert-log-compromised}. 
While there was little real-world impact from these incidents, they
showcase that full trust in CT logs is likely a mistake.

\subsection{Contribution and Structure}
Section~\ref{sec:background} introduces background on the theory and
practise of CT, as well as the anonymity network Tor.
Section~\ref{sec:adversary} motivates the intended attacker and presents a
unified threat model for CT and Tor.
Section~\ref{sec:base} describes the full CTor design that \emph{eliminates
all trust in the browser-recognized CT logs} by challenging them to prove
certificate inclusion cryptographically, and would
result in a \emph{single probabilistically-verified view of the CT log ecosystem
available from Tor's consensus}.  This view could be used by other browsers as
the basis of trust, \emph{greatly improving the security posture of the entire
web}.  The security analysis in Section~\ref{sec:analysis} shows that one of the
best bets for the attacker would be to take network-wide actions against Tor to
avoid public disclosure of certificate mis-issuance and log misbehavior.  Such
an attack is trivially detected, but it is hard to attribute unless reactive
defenses are enabled at the cost of trade-offs.

The full design involves many different components that add deployment burdens,
such as the requirement of reliable CT auditors that investigate suspected log
misbehavior further.  Therefore, we additionally propose two initial increments
that place \emph{some trust in the CT log ecosystem}.  The first increment
\emph{provides evidence to independent CT logs that fraudulent certificates were
presented while preserving privacy}.  This greatly impacts risk-averse attackers
because one part of their malicious behavior becomes transparent \emph{if the
randomly selected log operator is benign}.  For example, the targeted domain
name is disclosed as part of the cross-logged certificate, and awareness of the
event draws unwanted attention.

The next increment is minor from the perspective of Tor, but requires CT logs to
support an additional API.  Similar changes were proposed in the context of CT
gossip~\cite{minimal-gossip}.  If supported, Tor relays could expose both the
mis-issued certificates and the operators that promised to log them publicly
\emph{without the complexity of ever distinguishing between what is benign and
fraudulent}.
This API change happens to also build auditor infrastructure
directly into CT log software, paving the path towards the missing component of
the full design.  We argue that CTor \emph{can be deployed incrementally}:
	complete Firefox's CT enforcement~\cite{ffct},
	deploy certificate cross-logging, and
	eventually the full design can be put into operation.
Each CTor increment would \emph{greatly contribute to the open question of how
to reduce and/or eliminate trust in browser-recognized log operators}, which is
caused by the lack of an appropriate gossip mechanism as well as privacy issues
while interacting with the logs~\cite{minimal-gossip,nordberg,ct-with-privacy}.

We show that circuit-, bandwidth- and memory-\emph{overheads are modest} by
computing such estimates in Section~\ref{sec:performance}.  Therefore, we do not
investigate performance further in any experimental setting.
Section~\ref{sec:privacy} discusses privacy aspects of our design choices with
a focus on the essential role of the Tor network's distributed nature to
preserve user privacy as well as the overall security.  In gist,
\emph{a similar approach would be privacy-invasive without Tor}, e.g., if
adopted by Google Chrome.  Section~\ref{sec:related} outlines related work.
Section~\ref{sec:conclusion} concludes the paper.
