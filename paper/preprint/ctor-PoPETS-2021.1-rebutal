Dear reviewers,

Thank you for your time and comments.  We will address all of them, but respond
only to the main ones due to space limitations.

Our premise is CT as deployed in practise: logs are trusted based on the
enforcing web browsers' SCT-centric CT policies, which do not check for omitted
certificates or split-views.  This starting point in Tor Browser avoids breakage
on the web.  We consider it a win to then reduce [§4,§7] and eliminate [§6] such
trust incrementally.  We will update the paper to emphasize this as motivation.

Our threat model _is_ strong, significantly raising the bar when compared to
today's Tor Browser that does no CT checking.  Several logs misbehaved by
creating split-views [52], omitting certificates [31], and getting their secret
signing keys compromised [50].  Combine such incidents with a rogue CA, and we
get a modern DigiNotar-like attack.  Our attacker might be backed by a
nation-state actor or a criminal enterprise that wants to target a bulk of
users; not a specific individual.  This nuance will be clarified in §3.

We agree and already had plans to improve our design descriptions, e.g., phase
renaming and explaining parameter selection without going too much into CT
policy (better left external to a technical design paper).  We intend to
refactor accordingly.  Short comments:
  -->Delete-at-random: will be justified better without anonymity.
  -->Voting on constans: is a matter of flexibility, allows adapting to events.
  -->Independent CT logs and checking: such info can be in the consensus.

Note that our evaluations span security [§5,§6.2], privacy [§9], and performance
[§8].  We believe that no prototype or simulation is needed to show that the
involved overhead is modest*, but agree that we could improve our presentation
as well as add a paragraph on the expected impact of a ~MiB LRU/LFU cache.  We
simulated performance at first, but realized that the same conclusions could be
derived without it using a data set that will be an open access artifact for
reproducibility.  That said, a proof-of-concept implementation and shadow
emulation would be valuable future work.  Regarding the overhead of checking
SFOs towards STHs: signatures are checked once, fethed proofs are about 1KiB
(less bandwidth than §9), and verification requires 20-30 hashes per SFO.

There are 31 CT logs included in Chrome.  Their operators are Google, Cloudflare
and a few CAs, but anyone can apply to be an operator.  We will add this in
Appendix A, and clarify why LE is an interesting corner case.  We share the view
that LE is excellent, and will fix any text that insinuates otherwise.

Good observation about adding certificates through DNS in regular web browsers.
It is an interesting application of certificate cross-logging that goes beyond
CTor, which means that (mis)issued certificates are treated all the same (i.e.,
no complex user-agent protocol for suspected log misbehavior) and they make it
into the public domain faster since malicious logs can delay and omit inclusion.

*: 70% circuit overhead is acceptable due to being light-weight and short-lived
(confirmed by Tor developers).
